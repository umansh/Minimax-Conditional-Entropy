{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd6f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09526318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age Work Own_Apartment Credit_History response\n",
      "0       Old  Yes            No       Moderate      Yes\n",
      "1     Young  Yes            No           Good      Yes\n",
      "2       Old  Yes            No       Moderate      Yes\n",
      "3    Middle  Yes           Yes       Moderate      Yes\n",
      "4     Young  Yes            No       Moderate      Yes\n",
      "..      ...  ...           ...            ...      ...\n",
      "495     Old   No           Yes           Good      Yes\n",
      "496   Young   No            No           Good       No\n",
      "497     Old  Yes            No           Good       No\n",
      "498  Middle   No           Yes           Good      Yes\n",
      "499     Old   No           Yes      Excellent      Yes\n",
      "\n",
      "[500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#read csv file\n",
    "datasets = pd.read_csv('./Desktop/pythonProject/data.csv')\n",
    "datasets = datasets.iloc[:,1:6]\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46725a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9be4ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 1 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 1 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 0 1 0 0 1 0\n",
      " 1 0 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 0 1 0 1\n",
      " 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 1 0 1 1\n",
      " 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1\n",
      " 0 0 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1\n",
      " 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0\n",
      " 1 1 1 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 0 1 1\n",
      " 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 0 1 1 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(datasets['response'])\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cf9a983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Work  Own_Apartment  Credit_History  response\n",
      "0    1.0   1.0            0.0             2.0       1.0\n",
      "1    2.0   1.0            0.0             1.0       1.0\n",
      "2    1.0   1.0            0.0             2.0       1.0\n",
      "3    0.0   1.0            1.0             2.0       1.0\n",
      "4    2.0   1.0            0.0             2.0       1.0\n",
      "..   ...   ...            ...             ...       ...\n",
      "495  1.0   0.0            1.0             1.0       1.0\n",
      "496  2.0   0.0            0.0             1.0       0.0\n",
      "497  1.0   1.0            0.0             1.0       0.0\n",
      "498  0.0   0.0            1.0             1.0       1.0\n",
      "499  1.0   0.0            1.0             0.0       1.0\n",
      "\n",
      "[500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# ordinal encoder\n",
    "ord_enc = OrdinalEncoder()\n",
    "datasets = ord_enc.fit_transform(datasets)\n",
    "datasets = pd.DataFrame(datasets,columns=['Age','Work','Own_Apartment','Credit_History','response'])\n",
    "\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e4b8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate entopy\n",
    "def entropy(datasets, Y):\n",
    "\n",
    "    y_unique = list(set(Y))\n",
    "    # Calculate Prior Probability\n",
    "    prior = np.zeros(len(y_unique))\n",
    "    \n",
    "    prior =[]\n",
    "\n",
    "    for i in range(0, len(y_unique)):\n",
    "        prior_sum= sum(Y == y_unique[i]) / len(Y)\n",
    "        prior.append(prior_sum)\n",
    "\n",
    "    entropy = 0\n",
    "\n",
    "    for i in range(0, len(y_unique)):\n",
    "        entropy_sum = -1 * prior[i] * np.log2(prior[i])\n",
    "        entropy += entropy_sum\n",
    "\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c6e23b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy test: 0.9754383526853787\n"
     ]
    }
   ],
   "source": [
    "# calculate entropy\n",
    "entropy_test = entropy(datasets, Y)\n",
    "print('entropy test:',entropy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7c802fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to calculate conditional entropy\n",
    "\n",
    "def conditional_entropy(datasets, col, Y):\n",
    "    \n",
    "    var = list(datasets.columns)[col]\n",
    "    var_unique = list(set(datasets[var]))\n",
    "    \n",
    "    y_unique = list(set(Y))\n",
    "    y_len = len(y_unique)\n",
    "    \n",
    "    # calculate conditional probability\n",
    "    prob = np.zeros([len(var_unique), y_len + 1])\n",
    "\n",
    "    for i in range(0, len(var_unique)):\n",
    "        prob[i, 0] = sum(datasets[var] == var_unique[i]) / len(datasets[var])\n",
    "        \n",
    "    #print(conditional_prob)\n",
    "    for i in range(0, len(var_unique)):\n",
    "        for j in range(0, len(y_unique)):\n",
    "            prob[i, j + 1] = \\\n",
    "            datasets.loc[(datasets[var] == var_unique[i]) & (Y == y_unique[j]),].shape[0] / sum(\n",
    "                datasets[var] == var_unique[i])\n",
    "\n",
    "    # calculate conditional entropy\n",
    "    cond_entropy = 0\n",
    "    for i in range(0, len(var_unique)):\n",
    "        if (prob[i, 1] != 0) & (prob[i, 2] != 0):\n",
    "            enp = -1 * prob[i, 0] * (prob[i, 1] * np.log2(prob[i, 1]) + prob[i, 2] * np.log2(prob[i, 2]))\n",
    "            \n",
    "        elif (prob[i, 1] == 0) & (prob[i, 2] != 0):\n",
    "            enp = -1 * prob[i, 0] * (prob[i, 2] * np.log2(prob[i, 2], len(y_unique)))\n",
    "            \n",
    "        elif (prob[i, 1] != 0) & (prob[i, 2] == 0):\n",
    "            enp = -1 * prob[i, 0] * (prob[i, 1] * np.log2(prob[i, 1], len(y_unique)))\n",
    "\n",
    "        cond_entropy += enp\n",
    "\n",
    "    return cond_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02565669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cond_entropy: 0.934122296766307\n"
     ]
    }
   ],
   "source": [
    "cond_entropy = conditional_entropy(datasets=datasets, col=0, Y=Y)\n",
    "print('cond_entropy:',cond_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "038102a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "X = datasets.iloc[:,:4]\n",
    "X = np.array(X)\n",
    "\n",
    "Y=Y\n",
    "\n",
    "#read test data csv file\n",
    "test_data = pandas.read_csv('./Desktop/pythonProject/test1.csv')\n",
    "test_data = test_data.iloc[:,1:6]\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "X_test = ord_enc.fit_transform(test_data)\n",
    "X_test = pd.DataFrame(X_test,columns=['Age','Work','Own_Apartment','Credit_History','response'])\n",
    "X_test = X_test.iloc[:,:4]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "Y_test = label_encoder.fit_transform(test_data['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b037c5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1_cm: [[3 2]\n",
      " [3 7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X,Y)\n",
    "\n",
    "y_pred1 = model1.predict(X_test)\n",
    "\n",
    "w1_cm = confusion_matrix(Y_test, y_pred1)\n",
    "\n",
    "print('w1_cm:',w1_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7a1f6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2_cm: [[3 2]\n",
      " [3 7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model2 = GaussianNB()\n",
    "model2.fit(X,Y)\n",
    "\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "w2_cm = confusion_matrix(Y_test, y_pred2)\n",
    "\n",
    "print('w2_cm:',w2_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1fe163b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w3_cm: [[3 2]\n",
      " [1 9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "model3 = svm.SVC()\n",
    "model3.fit(X,Y)\n",
    "\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "w3_cm = confusion_matrix(Y_test, y_pred3)\n",
    "\n",
    "print('w3_cm:',w3_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44c847df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w4_cm: [[4 1]\n",
      " [1 9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "\n",
    "model4 = KNeighborsClassifier()\n",
    "model4.fit(X,Y)\n",
    "\n",
    "y_pred4 = model4.predict(X_test)\n",
    "\n",
    "w4_cm = confusion_matrix(Y_test, y_pred4)\n",
    "\n",
    "print('w4_cm:',w4_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cc05b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 0 0 1 1 1 1 0 1 0 0 0]\n",
      " [1 1 1 1 0 0 1 1 1 1 0 1 0 0 0]\n",
      " [1 1 0 1 1 1 1 1 1 1 0 1 0 0 1]\n",
      " [1 1 0 1 1 0 1 1 1 1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# create worker predicted matrix\n",
    "worker  = (y_pred1,y_pred2,y_pred3,y_pred4)\n",
    "\n",
    "worker = np.vstack(worker)\n",
    "\n",
    "print(worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b74e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(Y_test):\n",
    "\n",
    "    y_unique = list(set(Y_test))\n",
    "    \n",
    "    # Calculate probability\n",
    "    prior_prob = np.zeros(len(y_unique))\n",
    "    \n",
    "    prior_d = {}\n",
    "    for i in range(0, len(y_unique)):\n",
    "        prior= sum(Y_test == y_unique[i]) / len(Y_test)\n",
    "        prior_d[y_unique[i]] = prior\n",
    "\n",
    "    return prior_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "beb271d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.3333333333333333, 1: 0.6666666666666666}\n"
     ]
    }
   ],
   "source": [
    "#get probability of actual Y_test data set\n",
    "\n",
    "prob_y  = get_prob(Y_test)\n",
    "print(prob_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e032dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate probability of sum(log(p(P(Xij = xij|Yj = c))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
